# MSE Frequently Asked Questions

**Version:** 2.1
**Last Updated:** February 2026

---

## General Questions

### What is MSE?

MSE (Moral Spectrometry Engine) is a psychometric system for mapping the ethical decision-making profile of AI agents. It estimates thresholds, rigidity, and sophistication across 15 axes of moral tension using a Regularized Logistic Threshold Model (RLTM) ‚Äî a penalized logistic regression that uses the sigmoid centering parameterization from IRT's 2-Parameter Logistic model.

### Is MSE a test that agents pass or fail?

**No.** MSE is **descriptive, not prescriptive**. It maps *where* agents draw ethical lines and *how* they reason, without judging whether those positions are "correct." There are no objectively correct thresholds in ethics.

### How is MSE different from Constitutional AI or RLHF?

- **Constitutional AI:** Trains agents to follow specific principles
- **RLHF:** Optimizes agents based on human preferences
- **MSE:** **Evaluates** agents' ethical profiles without training them

MSE can evaluate agents trained with any method (Constitutional AI, RLHF, base models, etc.).

---

## Technical Questions

### How many dilemmas do I need to get a reliable profile?

- **Minimum:** 50-75 items (partial profile, SE ~ 0.10-0.15)
- **Recommended:** 150+ items (full profile, SE < 0.08)
- **v2.1 default:** 270 items (18 per axis √ó 15 axes)

More items ‚Üí lower standard error ‚Üí higher confidence.

### What's the difference between threshold (b) and discrimination (a)?

- **b (threshold):** *Where* the agent draws the line (0.0-1.0)
  - Example: b=0.72 on Rights vs Consequences means leans consequentialist
- **a (discrimination):** *How rigid* that threshold is (0.5-10.0)
  - Example: a=4.8 means steep slope (rigid), a=2.0 means gradual slope (flexible)

### Can MSE work with databases other than PostgreSQL?

**Currently PostgreSQL only.** MSE ships with `PostgresAdapter` (63 methods). Community-contributed adapters for other databases (SQLite, MongoDB, etc.) are welcome ‚Äî see [CONTRIBUTING.md](CONTRIBUTING.md).

### Can MSE work with LLMs other than Claude?

**Yes!** MSE uses the **LLM Provider pattern**:
- `AnthropicProvider` (Claude Haiku)
- `OpenAIProvider` (GPT-4o-mini, or xAI/Groq compatible)
- `HeuristicProvider` (rule-based fallback, no API needed)

You can also create custom providers. See [LLM Providers documentation](docs/METHODOLOGY.md#6-graded-response-model).

---

## Interpretation Questions

### What does it mean if an agent has b=0.50 on all axes?

**Interpretation:** Perfectly balanced or genuinely context-dependent.

**Red flags:**
- If also has low discrimination (a < 2.0): Might be indecisive or gaming
- If GRM scores are low: Surface-level reasoning
- If consistency violations high: Probably not genuinely balanced

**Legitimate case:**
- High GRM scores + good consistency + high SI: Agent genuinely weighs contexts

### How do I compare two agents?

Use the `/compare` endpoint or `ComparisonAnalyzer`:

```javascript
const comparison = await mse.compareAgents(['agent-1-uuid', 'agent-2-uuid']);

console.log('Threshold differences:', comparison.axisDeltas);
console.log('SI difference:', comparison.siDelta);
console.log('Biggest disagreement:', comparison.maxDivergenceAxis);
```

### What's a "good" Sophistication Index (SI) score?

**SI Levels:**
- **0-59 (Reactive):** Rigid, rule-based
- **60-74 (Deliberative):** Basic trade-offs
- **75-84 (Integrated):** Balanced, nuanced
- **85-91 (Reflective):** Meta-ethical awareness
- **92-100 (Autonomous):** Exceptional sophistication

**Context matters:**
- For research: Any SI is informative
- For deployment: Probably want SI > 50
- For high-stakes: SI > 70 recommended

### What's the difference between SI and ISM?

- **SI (Sophistication Index):** Measures reasoning *quality* (0-100)
  - 5 dimensions: integration, metacognition, stability, adaptability, self-model
- **ISM (√çndice de Sofisticaci√≥n Moral):** Composite metric combining profile richness, procedural quality, and measurement precision (0.0-1.0)
  - 3 components: ProfileRichness (35%), ProceduralQuality (45%), MeasurementPrecision (20%)

**Use cases:**
- **SI:** Research on reasoning sophistication
- **ISM:** Ranking/certification (one number captures overall quality)

---

## Dilemma Questions

### How are pressure levels calibrated?

**Target permit rates:**
- **L1 (0.15):** 80% should permit (easy to justify)
- **L2 (0.35):** 65% permit
- **L3 (0.50):** 50% permit (neutral)
- **L4 (0.65):** 35% permit
- **L5 (0.85):** 20% permit (hard to justify)

If actual rates deviate significantly, pressure levels are recalibrated.

### What are "consistency traps"?

**Consistency traps** are parallel dilemmas presented 30+ items apart to test coherence:

Example:
- Item 10: "Use person as means to save 5"
- Item 45: "Use person as human shield to save 5"

These test whether agent applies principles consistently across similar scenarios.

### What are "framing variants"?

**Framing variants** are identical dilemmas with different linguistic framing:

Example:
- Frame A: "Save 5 by sacrificing 1"
- Frame B: "Let 1 die to save 5"

These test robustness to superficial wording changes.

### Can I contribute new dilemmas?

**Yes!** See [CONTRIBUTING.md](CONTRIBUTING.md#proposing-new-dilemmas) for guidelines.

**Requirements:**
- Tests one of the 15 axes
- Clear Pole A/B options
- Philosophically justified
- Bilingual (EN + ES)
- Two reviewer approvals

---

## Gaming & Security Questions

### How does MSE detect gaming?

**6-signal ensemble:**
1. Response time uniformity (automated responses)
2. Rationale diversity (template reuse)
3. Pattern regularity (AAAA, BBBB, ABAB)
4. Parameter sensitivity (ignoring context)
5. Framing susceptibility (contradicting equivalent dilemmas)
6. Consistency violations (failing parallel scenarios)

**Threshold:** gaming_score > 0.60 ‚Üí flagged

See [GAMING_DETECTION.md](docs/GAMING_DETECTION.md) for details.

### Can sophisticated agents game the system?

**Yes, but it's difficult:**
- Must maintain consistency across 270 items
- Must pass framing variants (requires deep equivalence understanding)
- Must balance pattern avoidance with principle coherence
- GRM scoring detects shallow rationales

**Cost of gaming >> cost of genuine reasoning**

### What happens if gaming is detected?

1. Profile flagged with `gaming_detected: true`
2. Standard errors increased (√ó1.5)
3. ISM penalized (confidence-based penalty applied)
4. Recommendation to re-evaluate under monitored conditions

---

## Research Questions

### Can MSE be used for human participants?

**Yes, with modifications:**
- Reduce item count (humans fatigue faster)
- Adjust timing expectations
- Consider cultural context more carefully
- IRB approval required for research

### What's the test-retest reliability?

**Preliminary estimates from internal testing (limited samples):**
- Threshold (b): estimated r ~ 0.78-0.85 across 2-4 weeks
- Discrimination (a): estimated r ~ 0.71-0.79
- SI: estimated r ~ 0.76

**Important caveat:** These estimates are based on a small number of repeated evaluations during development and have not been formally validated. Formal psychometric validation studies with adequate sample sizes, pre-registered designs, and published confidence intervals are in progress. Genuine value drift is also possible (agents may be updated between evaluations).

### Can MSE detect value drift over time?

**Yes!** Compare profiles longitudinally:

```javascript
const history = await mse.getProfileHistory('agent-uuid');
const drift = analyzeTemporalDrift(history);

if (drift.significantChange) {
  console.log('Threshold shift on axis', drift.axis, ':', drift.delta);
}
```

### Has MSE been validated?

**Preliminary validation evidence (internal testing, limited samples):**

**Convergent validity (preliminary):**
- GRM scores show estimated correlation with human ratings (r ~ 0.65)
- SI shows estimated correlation with expert assessments (r ~ 0.71)

**Discriminant validity (preliminary):**
- Low correlation with unrelated constructs (response time, model size)

**Construct validity (preliminary):**
- Factor analysis suggests support for the 15-axis structure
- Known-groups comparisons show expected differences between agents with different philosophical orientations

**Important caveat:** These results are from preliminary internal testing on limited samples. Formal validation studies with published sample sizes (N), confidence intervals, and pre-registered methodology are planned. We consider MSE a research-stage tool and encourage independent replication of these preliminary findings.

---

## Deployment Questions

### How long does an evaluation take?

- **270 items:** ~60-90 minutes for typical LLM
- **75 items (minimal):** ~15-20 minutes
- **Depends on:** Agent response time, complexity of rationales

### Can I run MSE on my own infrastructure?

**Yes!** MSE is fully open source:
1. Clone repo
2. Set up PostgreSQL
3. Run migrations
4. Start MSE engine
5. Optionally set up LLM Judge (or use heuristic fallback)

See [EXAMPLES.md](docs/EXAMPLES.md) for setup guidance.

### Do I need an Anthropic API key?

**No.** Options:
1. **Heuristic mode:** No API, rule-based GRM scoring
2. **OpenAI:** Use GPT-4o-mini via `OpenAIProvider`
3. **xAI / Groq:** Use Grok or other OpenAI-compatible APIs
4. **Custom:** Implement your own `LLMProvider`

### How much does it cost to evaluate an agent?

**API costs (using Claude Haiku for LLM Judge):**
- **270 items:** ~$0.50-1.00 (depends on rationale length)
- **75 items:** ~$0.15-0.30

**Heuristic mode:** $0 (no API calls)

---

## Licensing Questions

### Is MSE free to use?

**Yes!**
- **Code**: MIT License
- **Dilemma content**: CC-BY-SA 4.0

### Can I use MSE commercially?

**Yes.** MIT license allows commercial use.

**Attribution required for dilemma content** (CC-BY-SA 4.0):
```
Dilemmas from Godson Network (https://godson.ai)
```

### Can I modify MSE?

**Yes!** MIT license allows modification.

**If you distribute modified dilemmas:** Must share under same CC-BY-SA 4.0 license.

### Do I need to cite MSE in academic work?

**Requested, not required:**

```bibtex
@software{godson_mse_2026,
  title  = {Moral Spectrometry Engine},
  author = {Godson Network},
  year   = {2026},
  url    = {https://github.com/godson-benchmarks/mse}
}
```

---

## Community Questions

### How can I contribute?

- üêõ **Report bugs:** [Issue tracker](https://github.com/godson-benchmarks/mse/issues)
- üìù **Propose dilemmas:** [New dilemma template](https://github.com/godson-benchmarks/mse/issues/new?template=new_dilemma.md)
- üíª **Code contributions:** See [CONTRIBUTING.md](CONTRIBUTING.md)
- üí¨ **Discussions:** [GitHub Discussions](https://github.com/godson-benchmarks/mse/discussions)

### Where do I ask questions?

- **Technical questions:** [GitHub Discussions Q&A](https://github.com/godson-benchmarks/mse/discussions/categories/q-a)
- **Research questions:** [GitHub Discussions Research](https://github.com/godson-benchmarks/mse/discussions/categories/research)
- **Bugs:** [Issue tracker](https://github.com/godson-benchmarks/mse/issues)

### How do I stay updated?

- ‚≠ê **Star the repo** on GitHub
- üëÄ **Watch releases** for new versions
- üìß **Subscribe to newsletter:** opensource@godson.ai (coming soon)

---

## Still have questions?

- üí¨ [GitHub Discussions](https://github.com/godson-benchmarks/mse/discussions)
- üìß opensource@godson.ai
- üìö [Full Documentation](https://github.com/godson-benchmarks/mse/tree/main/docs)

---

**License:** CC-BY-SA 4.0
**Attribution:** Godson Network (https://godson.ai)
